{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble de modelos para predecir precios de acciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías generales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import datetime as dt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Librerías LSTM\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Librerías Skforecast\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para acceder lago de datos\n",
    "silver = './data/silver/stock-prices/'\n",
    "gold = './data/gold/portfolio-optimization/'\n",
    "silver_table = 'stock_prices.csv'\n",
    "gold_table = 'portfolio_optimization.csv'\n",
    "\n",
    "# Parámetros del modelo\n",
    "ticker = ['AAPL','MSFT','AMZN','TSLA','GOOGL','GOOG','NVDA','BRK-B','META','UNH'] \n",
    "metric_to_predict = 'Adj Close'\n",
    "days_to_predict = 3 # Short-term future days to predict\n",
    "pred_span_days = 60 # Set the number of days used for prediction\n",
    "backward_steps = 180 # Set the backward steps to go from the last observation available\n",
    "cpu_list = [i for i in ticker]\n",
    "n_features = len(cpu_list)\n",
    "\n",
    "# Lectura y transformación de datos\n",
    "data = pd.read_csv(silver+silver_table)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "df_c = pd.pivot_table(data, values=metric_to_predict, columns=['Ticker'], index=data.index)\n",
    "df_c = df_c[ticker]\n",
    "\n",
    "# Construcción de modelo para imputar missing values\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# Ajuste de modelo para imputar missing values por ticker\n",
    "for i in ticker:\n",
    "      imputer.fit(df_c[[i]])\n",
    "      df_c[i] = imputer.transform(df_c[[i]]).ravel()\n",
    "\n",
    "# Extracción de porción de datos a usar\n",
    "df_train = df_c.iloc[-backward_steps:]\n",
    "df_test = df_c.iloc[backward_steps:]\n",
    "\n",
    "def inverse_transform(y):\n",
    " y_reshaped = y.reshape(-1, y.shape[-1])\n",
    " y_inverse = scaler.inverse_transform(y_reshaped)\n",
    " return y_inverse\n",
    "\n",
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequence)): \n",
    "   lag_end = i + look_back\n",
    "   forecast_end = lag_end + forecast_horizon\n",
    "   if forecast_end > len(sequence):\n",
    "     break\n",
    "   seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "   X.append(seq_x)\n",
    "   y.append(seq_y)\n",
    " return np.array(X), np.array(y)\n",
    "\n",
    "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
    " mse_ = tf.keras.losses.MeanSquaredError()\n",
    " mae_ = tf.keras.losses.MeanAbsoluteError()\n",
    " mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    " mae = mae_(y_test_inverse,yhat_inverse)\n",
    " print('mae:', mae)\n",
    " mse = mse_(y_test_inverse,yhat_inverse)\n",
    " print('mse:', mse)\n",
    " mape = mape_(y_test_inverse,yhat_inverse)\n",
    " print('mape:', mape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(df_train[cpu_list])\n",
    "scaled_test = scaler.transform(df_test[cpu_list])\n",
    "scaled_pred = scaler.transform(df_c[cpu_list])\n",
    "\n",
    "X_train, y_train = split_sequence(scaled_train, look_back=pred_span_days, forecast_horizon=days_to_predict)\n",
    "X_test, y_test = split_sequence(scaled_test, look_back=pred_span_days, forecast_horizon=days_to_predict)\n",
    "X_pred, y_pred = split_sequence(scaled_pred, look_back=pred_span_days, forecast_horizon=days_to_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM\n",
    "def model2(units, dropout_rate):\n",
    "    model_enc_dec_cnn = Sequential()\n",
    "    model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=9, activation='relu', input_shape=(pred_span_days, n_features)))\n",
    "    model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=11, activation='relu'))\n",
    "    model_enc_dec_cnn.add(MaxPooling1D(pool_size=2))\n",
    "    model_enc_dec_cnn.add(Flatten())\n",
    "    model_enc_dec_cnn.add(RepeatVector(days_to_predict))\n",
    "    model_enc_dec_cnn.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "    model_enc_dec_cnn.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model_enc_dec_cnn.add(TimeDistributed(Dense(n_features)))\n",
    "    model_enc_dec_cnn.compile(loss='mse', optimizer='adam')\n",
    "    return model_enc_dec_cnn\n",
    "\n",
    "units = 128\n",
    "epochs = 25\n",
    "dropout_rate = 0.2\n",
    "batch_size = 32\n",
    "validation = 0.05\n",
    "\n",
    "model_enc_dec_cnn = model2(128,0.2)\n",
    "model_enc_dec_cnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation)\n",
    "yhat = model_enc_dec_cnn.predict(X_test, verbose=0)\n",
    "yhat_inverse = inverse_transform( yhat)\n",
    "y_test_inverse = inverse_transform(y_test)\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "CNN_LSTM_train = yhat_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "forecaster_reg = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = RandomForestRegressor(random_state=123, bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=10),\n",
    "                    lags               = 7\n",
    "                )\n",
    "forecaster_reg.fit(df_train)\n",
    "RDM_FRST_train = forecaster_reg.predict(days_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "forecaster_xgb = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = XGBRegressor(random_state=123, learning_rate=0.1, max_depth=3, max_iter=100),\n",
    "                    lags               = 14\n",
    "                )\n",
    "forecaster_xgb.fit(df_train)\n",
    "XGB_train = forecaster_xgb.predict(days_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble\n",
    "\n",
    "# Cambio de estructura de predicciones\n",
    "CNN_LSTM_train = list(CNN_LSTM_train[-days_to_predict:].reshape(-1))\n",
    "RDM_FRST_train = list(RDM_FRST_train.values.reshape(-1))\n",
    "XGB_train = list(XGB_train.values.reshape(-1))\n",
    "TEST_train = list(df_test[-days_to_predict:].values.reshape(-1))\n",
    "preds = np.stack([\n",
    "    CNN_LSTM_train, RDM_FRST_train, XGB_train\n",
    "])\n",
    "preds = pd.DataFrame(preds).transpose()\n",
    "\n",
    "# Entrenamiento\n",
    "stacker = LinearRegression()\n",
    "stacker.fit(X=preds, y=TEST_train)\n",
    "\n",
    "# Coeficientes del modelo ensamble\n",
    "stacker.intercept_, stacker.coef_\n",
    "\n",
    "# Predicción\n",
    "STCK = stacker.predict(preds)\n",
    "evaluate_forecast(TEST_train, STCK)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para predecir\n",
    "def predict(num_prediction, model):\n",
    "    prediction_list = data[-pred_span_days+1:][metric_to_predict]\n",
    "    for _ in range(days_to_predict):\n",
    "        yhat = model_enc_dec_cnn.predict(X_pred, verbose=0)\n",
    "        yhat_inverse = inverse_transform(yhat)[0]\n",
    "        prediction_list = np.append(prediction_list, yhat_inverse)\n",
    "    prediction_list = prediction_list[pred_span_days-1:]\n",
    "    return prediction_list\n",
    "    \n",
    "def predict_dates(num_prediction):\n",
    "    last_date = data.index[len(data.index)-1]\n",
    "    prediction_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()\n",
    "    return prediction_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM\n",
    "def model2(units, dropout_rate):\n",
    "    model_enc_dec_cnn = Sequential()\n",
    "    model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=9, activation='relu', input_shape=(pred_span_days, n_features)))\n",
    "    model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=11, activation='relu'))\n",
    "    model_enc_dec_cnn.add(MaxPooling1D(pool_size=2))\n",
    "    model_enc_dec_cnn.add(Flatten())\n",
    "    model_enc_dec_cnn.add(RepeatVector(days_to_predict))\n",
    "    model_enc_dec_cnn.add(LSTM(units, activation='relu', return_sequences=True))\n",
    "    model_enc_dec_cnn.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model_enc_dec_cnn.add(TimeDistributed(Dense(n_features)))\n",
    "    model_enc_dec_cnn.compile(loss='mse', optimizer='adam')\n",
    "    return model_enc_dec_cnn\n",
    "\n",
    "units = 128\n",
    "epochs = 25\n",
    "dropout_rate = 0.2\n",
    "batch_size = 32\n",
    "validation = 0.05\n",
    "\n",
    "model_enc_dec_cnn = model2(128,0.2)\n",
    "model_enc_dec_cnn.fit(X_pred, y_pred, epochs=epochs, batch_size=batch_size, validation_split=validation)\n",
    "forecast = predict(days_to_predict, model_enc_dec_cnn)\n",
    "forecast_dates = predict_dates(days_to_predict)\n",
    "CNN_LSTM = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "forecaster_reg = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = RandomForestRegressor(random_state=123, bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=10),\n",
    "                    lags               = 7\n",
    "                )\n",
    "forecaster_reg.fit(df_c)\n",
    "RDM_FRST = forecaster_reg.predict(days_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "forecaster_xgb = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = XGBRegressor(random_state=123, learning_rate=0.1, max_depth=3, max_iter=100),\n",
    "                    lags               = 14\n",
    "                )\n",
    "forecaster_xgb.fit(df_c)\n",
    "XGB = forecaster_xgb.predict(days_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble\n",
    "\n",
    "# Cambio de estructura de predicciones\n",
    "RDM_FRST = list(RDM_FRST.values.reshape(-1))\n",
    "XGB = list(XGB.values.reshape(-1))\n",
    "preds = np.stack([\n",
    "    CNN_LSTM, RDM_FRST, XGB\n",
    "])\n",
    "preds = pd.DataFrame(preds).transpose()\n",
    "\n",
    "# Predicción\n",
    "STCK = stacker.predict(preds)\n",
    "preds.rename(columns={0:'LSTM',1:'RF',2:'XGB'},inplace=True)\n",
    "preds['Pred'] = STCK\n",
    "\n",
    "t = []\n",
    "for j in range(days_to_predict):\n",
    "    t.append(cpu_list)\n",
    "\n",
    "d = []\n",
    "for i in cpu_list:\n",
    "    d.append(forecast_dates[1:])\n",
    "\n",
    "preds['Ticker'] = np.array(t).reshape(-1)\n",
    "d = np.array(d).reshape(-1)\n",
    "preds.index = d\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficación de una muestra de los datos predichos\n",
    "trace1 = go.Scatter(\n",
    "    x = df_c.index,\n",
    "    y = df_c['AAPL'],\n",
    "    mode = 'lines',\n",
    "    name = 'TEST'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = preds.index,\n",
    "    y = preds[preds['Ticker']=='AAPL']['RF'],\n",
    "    mode = 'lines',\n",
    "    name = 'CNN'\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title = 'Stock',\n",
    "    xaxis = {'title' : 'Date'},\n",
    "    yaxis = {'title' : 'Values'}\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
